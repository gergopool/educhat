Expected SARSA has the update 
\[
    Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \alpha \left[ R_{t+1} + \gamma \E{}[Q(S_{t+1}) | S_{t+1}] - Q(S_t, A_t)\right]
\]

The update for $S_t, A_t$ is 
\[
    R_{t+1} + \gamma \sum_a \pi(a|S_{t+1}) Q(S_{t+1}, a) - Q(S_t, A_t).
\]
Double expected SARSA would be keeping two $Q$ arrays and updating one of them each timestep, chosen with equal probability.\\

For an $\varepsilon$-greedy policy we would increment $Q_1(S_t, A_t)$ by
\begin{equation}
    \alpha \left[ R_{t+1} + \gamma \left( \frac{\varepsilon}{|\mathcal{A}(a)|} \sum_a Q_2(S_{t+1}, a) + (1-\varepsilon)\max_a\{Q_2(S_{t+1}, a)\} \right) - Q_1(S_t, A_t)  \right]
\end{equation}
and the same with 1 and 2 reversed.
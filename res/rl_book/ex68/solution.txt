The state C happens to have een initialised to its true value. As training starts, updates occur on outer states (making them more accurate individually) which makes the error across all states reduce. This happens until the residual inaccuracies in the outer states propagate to C. The higher values of $\alpha$ make this effect more pronounced, because the value estimate for C changes more readily in these cases.